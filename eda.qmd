---
title: "Exploratory Data Analysis (EDA)"
subtitle: "Visual and Statistical Insights from Job Market Data"
author:
  - name: "Anu Sharma, Cindy Guzman, Gavin Boss"
    affiliations:
      - id: bu
        name: Boston University
        city: Boston
        state: MA
date: "2025-10-09"
format:
  html:
    theme: lux
    toc: true
    toc-depth: 2
    number-sections: true
    code-fold: true
    smooth-scroll: true
    code-overflow: wrap
execute:
  echo: true
  eval: true
  warning: false
  message: false
---

### Overview

This Exploratory Data Analysis (EDA) examines job postings from Lightcast to uncover salary trends, experience requirements, remote work dynamics, and skill demand across Business Analytics (BA), Data Science (DS), and Machine Learning (ML) roles.
The analysis prepares the dataset for modeling and provides statistical and visual insights that guide the regression and feature engineering stages of the project.

Specifically, this section covers:

- Data preparation and cleaning ‚Äì handling duplicates, renaming key columns, converting data types, and computing an Average_Salary variable

- Salary distribution and outliers ‚Äì visualizing the spread of compensation and identifying high-paying ML and senior roles

- Experience and salary relationships ‚Äì analyzing how required years of experience influence pay across remote and hybrid work types

- Role-based salary comparison ‚Äì comparing median salaries for BA, DS, and ML roles

- Remote work trends ‚Äì exploring how work flexibility impacts compensation

- Top skill frequencies ‚Äì identifying the most in-demand technical and analytical skills in job descriptions

- Feature correlations ‚Äì assessing relationships between numeric variables such as salary and experience to inform model selection

Together, these insights establish a clear understanding of labor market patterns and help define which features are most predictive for the upcoming salary regression models.


#### Load and Prepare Data
```{python}
# | echo: true
# | eval: true

import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import plotly.figure_factory as ff
import plotly.io as pio
import json
import re
from collections import Counter

pio.templates.default = "plotly_white"
pio.renderers.default = "iframe_connected"

# === Load data from CSV ===
df = pd.read_csv("data/lightcast_job_postings.csv", low_memory=False)
# print(f"Dataset loaded: {len(df):,} rows, {len(df.columns)} columns")

# --- Detect & drop duplicate columns ---
# --- Detect & fully clean duplicate-like columns ---
# Normalize column names: strip whitespace and hidden characters
df.columns = df.columns.str.strip().str.replace(r"\s+", " ", regex=True)

# Collapse exact duplicates after cleanup
before_cols = len(df.columns)
df = df.loc[:, ~df.columns.duplicated()]
after_cols = len(df.columns)

# print(f"üßπ Cleaned column names: removed {before_cols - after_cols} duplicate(s).")
# print("Unique columns now:", len(df.columns))

# --- Convert numeric columns safely ---
for col in ["SALARY_FROM", "SALARY_TO", "MIN_YEARS_EXPERIENCE", "MAX_YEARS_EXPERIENCE"]:
    if col in df.columns:
        df[col] = pd.to_numeric(df[col], errors="coerce")

# --- Compute average salary (avoid string concat) ---
if {"SALARY_FROM", "SALARY_TO"}.issubset(df.columns):
    df["Average_Salary"] = df[["SALARY_FROM", "SALARY_TO"]].mean(axis=1, skipna=True)

# --- Clean and rename (safely) ---
rename_map = {
    "REMOTE_TYPE_NAME": "REMOTE_GROUP",
    "STATE_NAME": "STATE",
    "LOT_V6_OCCUPATION_GROUP_NAME": "ROLE_GROUP"
}

# Only rename columns that won't create duplicates
for old, new in rename_map.items():
    if old in df.columns and new not in df.columns:
        df.rename(columns={old: new}, inplace=True)
    elif old in df.columns and new in df.columns:
      # print(f"‚ö†Ô∏è Skipping rename '{old}' ‚Üí '{new}' to avoid duplicate column name.")
      pass


# --- Drop invalid rows early ---
if "Average_Salary" in df.columns:
    df = df[df["Average_Salary"].notna() & (df["Average_Salary"] > 0)]

# --- Downsample if dataset is large ---
if len(df) > 5000:
    df = df.sample(5000, random_state=42)

# print(f"‚úÖ Loaded {len(df)} rows safely with {len(df.columns)} unique columns.")
```

### Data Preparation and Cleaning

The dataset used for this analysis was sourced from Lightcast job postings, containing thousands of listings across Business Analytics (BA), Data Science (DS), and Machine Learning (ML) roles.
To ensure data quality and consistency:

Column Normalization: Extra spaces and hidden characters were stripped from column names to avoid mismatches and duplicates.

Duplicate Removal: Identical columns were collapsed to retain only unique fields.

Type Conversion: Numeric columns such as SALARY_FROM, SALARY_TO, MIN_YEARS_EXPERIENCE, and MAX_YEARS_EXPERIENCE were coerced into numeric format, with non-numeric values safely converted to NaN.

Average Salary Calculation: A new feature, Average_Salary, was computed as the mean of the salary range for each posting to simplify analysis.

Column Renaming: Key columns were standardized (REMOTE_TYPE_NAME ‚Üí REMOTE_GROUP, STATE_NAME ‚Üí STATE, LOT_V6_OCCUPATION_GROUP_NAME ‚Üí ROLE_GROUP) for clarity.

Invalid Data Removal: Rows with missing or non-positive salaries were dropped.

Downsampling: For performance, the dataset was randomly reduced to 5,000 representative rows, preserving the statistical diversity of the original population.

This preprocessing established a clean, consistent dataset suitable for visualization and modeling.

```{python}
fig = px.histogram(
    df, x="Average_Salary", nbins=40,
    color_discrete_sequence=["#187145"],
    title="Distribution of Average Salaries"
)
fig.update_layout(
    xaxis_title="Average Salary ($ USD)",
    yaxis_title="Number of Job Postings",
    template="plotly_white"
)
fig
```

### Salary Distribution and Outliers
Salaries are right-skewed ‚Äî most roles pay under $150K, but select senior and ML-focused positions exceed $200K, highlighting outlier opportunities for experienced professionals.

```{python}
fig = px.scatter(
    df,
    x="MIN_YEARS_EXPERIENCE",
    y="Average_Salary",
    color="REMOTE_GROUP",
    trendline="ols",
    title="Salary vs. Minimum Experience by Remote Type",
    height=500
)
fig.update_layout(template="plotly_white")
fig
```

### Salary vs Experience
Salary shows a positive correlation with experience, particularly for hybrid and remote roles ‚Äî suggesting advanced or flexible positions are often compensated higher.

```{python}
fig = px.box(
    df,
    x="ROLE_GROUP",
    y="Average_Salary",
    color="ROLE_GROUP",
    color_discrete_sequence=["#187145", "#45A274", "#79C99E"],
    title="Salary Comparison Across Role Categories"
)
fig.update_layout(template="plotly_white")
fig
```

### Salary by Role Category (BA / DS / ML)
Machine Learning roles exhibit the highest median salaries, followed by Data Science and Business Analytics. This validates using ROLE_GROUP as a key feature in regression modeling.


```{python}
fig = px.box(
    df,
    x="REMOTE_GROUP",
    y="Average_Salary",
    color="REMOTE_GROUP",
    color_discrete_sequence=["#45A274", "#79C99E", "#A7D9C9"],
    title="Salary Distribution by Remote Work Type"
)
fig.update_layout(template="plotly_white")
fig
```

### Remote Work vs Salary Trends
Remote roles tend to offer higher median salaries compared to onsite jobs, supporting modern hybrid compensation trends in data-driven fields.

```{python}
# --- Top Skills Visualization (Safe Version) ---

skills_column = None
for col in ["SKILLS_NAME", "COMMON_SKILLS_NAME", "SPECIALIZED_SKILLS_NAME", "SOFTWARE_SKILLS_NAME"]:
    if col in df.columns:
        skills_column = col
        break

if skills_column:
    # print(f"‚úÖ Using '{skills_column}' for skill frequency analysis.")
    
    skills_flat = [
        s.strip()
        for sublist in df[skills_column].dropna().astype(str).str.split(',')
        for s in sublist if s.strip()
    ]

    skill_counts = pd.DataFrame(
        Counter(skills_flat).most_common(15),
        columns=["Skill", "Count"]
    )

    fig = px.bar(
        skill_counts,
        x="Skill",
        y="Count",
        title=f"Top 15 Most Frequent Skills ({skills_column})",
        color_discrete_sequence=["#187145"]
    )
    fig.update_layout(template="plotly_white")
    fig
else:
    print("‚ö†Ô∏è No skill-related column found ‚Äî skipping skills frequency plot.")
```

### Top Skills Frequency
Python, SQL, and Machine Learning dominate job descriptions, indicating their critical role in employability and forming the foundation for the modeling phase.

```{python}
corr_cols = ["Average_Salary", "MIN_YEARS_EXPERIENCE", "MAX_YEARS_EXPERIENCE"]
corr = df[corr_cols].corr().round(2)

fig = ff.create_annotated_heatmap(
    z=corr.values,
    x=corr.columns.tolist(),
    y=corr.columns.tolist(),
    colorscale='greens',
    showscale=True
)
fig.update_layout(title="Feature Correlation Matrix", template="plotly_white", height=450)
fig
```

### Correlation Heatmap
Salary correlates moderately with both minimum and maximum experience, confirming their inclusion in regression modeling.
We‚Äôll rely on additional categorical encodings (e.g., REMOTE_GROUP, ROLE_GROUP) for predictive depth.
